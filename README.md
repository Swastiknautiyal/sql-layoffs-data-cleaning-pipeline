# sql-layoffs-data-cleaning-pipeline
End-to-end SQL project cleaning and standardizing a layoffs dataset (duplicates removal, null handling, date formatting, standardization, and final cleaned dataset ready for analysis).
<h1 align="center">ðŸ§¹ SQL Layoffs Data Cleaning Pipeline</h1>
<p align="center">
  End-to-end SQL project to clean, standardize, and prepare a layoffs dataset for analysis using <b>MySQL</b>.
</p>

<p align="center">
  <img alt="SQL" src="https://img.shields.io/badge/SQL-Data%20Cleaning-orange">
  <img alt="MySQL" src="https://img.shields.io/badge/Database-MySQL-blue?logo=mysql">
  <img alt="Kaggle" src="https://img.shields.io/badge/Data-Kaggle-lightblue?logo=kaggle">
  <img alt="GitHub" src="https://img.shields.io/badge/Version%20Control-GitHub-black?logo=github">
  <img alt="Status" src="https://img.shields.io/badge/Status-Completed-brightgreen">
  <img alt="License" src="https://img.shields.io/badge/License-MIT-yellow">
</p>

---

## ðŸ“– Overview
This project demonstrates how to clean and standardize a **layoffs dataset** sourced from Kaggle.  
The goal is to transform messy raw data into a **clean, reliable, analysis-ready dataset** using SQL best practices.
